import cv2
import dlib
import numpy as np
import os


ruta_video = r"Nuevo_codigo\Videos\quieto_rapido.mp4"

os.startfile(r'video_resumen_labios.mp4')

# Carga el detector de rostros y el predictor de puntos faciales
detector = dlib.get_frontal_face_detector()
predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')

# Cargar el video
video = cv2.VideoCapture(ruta_video)
fps = int(video.get(cv2.CAP_PROP_FPS))
width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))
height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))
threshold = 2.0  # Umbral para detectar cambios significativos en los labios

# Configurar el escritor de video en formato MP4
fourcc = cv2.VideoWriter_fourcc(*'mp4v')
output_video = cv2.VideoWriter('video_resumen_labios.mp4', fourcc, fps, (width, height))

previous_lip_points = None
frame_number = 0

while True:
    ret, frame = video.read()
    if not ret:
        break

    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    faces = detector(gray)

    for face in faces:
        landmarks = predictor(gray, face)

        # Extraer puntos de los labios (48-67)
        lip_points = np.array([(landmarks.part(i).x, landmarks.part(i).y) for i in range(48, 68)])

        if previous_lip_points is not None:
            # Calcular la distancia promedio entre los puntos actuales y los anteriores
            distances = np.linalg.norm(lip_points - previous_lip_points, axis=1)
            mean_distance = np.mean(distances)

            # Si el cambio es significativo, guarda el cuadro en el video resumen
            if mean_distance > threshold:
                output_video.write(frame)

        previous_lip_points = lip_points
    frame_number += 1

# Liberar los recursos
video.release()
output_video.release()

print("Video resumen creado: video_resumen_labios.mp4")
