import cv2
import dlib
import math
import time
import os

os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'

import tensorflow as tf
print(tf.executing_eagerly())
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import TimeDistributed, Conv1D, MaxPooling1D, Flatten, LSTM, Dropout, BatchNormalization, Dense, Masking
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.utils import to_categorical
from sklearn.model_selection import train_test_split


TF_ENABLE_ONEDNN_OPTS=0

import matplotlib.pyplot as plt

import numpy as np
from PIL import Image

FIN_BLOQUE = "################################################################################"
FIN_ELEMENTO = "########"

# Cargar el detector de caras y el predictor de puntos clave de Dlib
detector = dlib.get_frontal_face_detector()
predictor = dlib.shape_predictor("D:\Escritorio\Master\PrimerCuatri\EXTRACTION_DE_DONNEES\Red_Habla\shape_predictor_68_face_landmarks.dat")

#key_points_interesantes = [48, 49, 50, 52, 53, 54 , 55, 56, 58, 59, 62, 66]
key_points_interesantes = [48, 49, 50, 51, 52, 53, 54 , 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67]

# Iniciar la captura de video
cap = cv2.VideoCapture(0)
cap.set(cv2.CAP_PROP_FPS, 60)

threshold = 1 # Umbral para detectar cambios significativos en los labios

#############################################################
# Extraccion de datos

def lips_points_labios(imagen):
    lips_points = []

    # Detectar caras
    faces = detector(imagen)

    # Para cada cara detectada, predecir los puntos clave
    for face in faces:
        landmarks = predictor(imagen, face)

        lips_points = []

        for n in key_points_interesantes:  # Los índices de los puntos de los labios en el modelo de 68 puntos
            x = landmarks.part(n).x
            y = landmarks.part(n).y
            lips_points.append((x, y))
            
        break

    return np.array(lips_points)

def angulo_boca(comisura_labio_izq, comisura_labio_der):
    dx = comisura_labio_der[0] - comisura_labio_izq[0]
    dy = comisura_labio_der[1] - comisura_labio_izq[1]

    # Calcula el ángulo en radianes
    angulo_radianes = math.atan2(dy, dx)

    # Convierte el ángulo a grados
    angulo_grados = math.degrees(angulo_radianes)

    return angulo_grados

def rotar_imagen_angulo_0(imagen,angulo,point1,point2):
    centro_punto_D1 = (point1[0]+point2[0])/2
    centro_punto_D2 = (point1[1]+point2[1])/2
    #center = (int((point1[0]+point2[0])//2),int((point1[1]+point2[1])//2))
    centro = (centro_punto_D1,centro_punto_D2)
    rotation_matrix = cv2.getRotationMatrix2D(centro, angulo, 1.0)
    imagen_rotada = cv2.warpAffine(imagen, rotation_matrix, (imagen.shape[1], imagen.shape[0]))
    return imagen_rotada

#############################################################
# Normalizacion

"""
def normalize_keypoints(all_lips_points):
    all_lips_points = np.array(all_lips_points)
    min_vals = all_lips_points.min(axis=0)
    max_vals = all_lips_points.max(axis=0)
    normalized_points = (all_lips_points - min_vals) / (max_vals - min_vals)
    return normalized_points
"""

def normalize_keypoints_frame(points):
    """
    Normaliza un conjunto de keypoints en un frame centrando por el centroide
    y escalando por la distancia máxima desde el centroide.
    
    Args:
    - points (numpy array): Array de tamaño (K, 2), donde:
        K: Número de keypoints en un frame.
        2: Coordenadas (x, y).
    
    Returns:
    - normalized_points (numpy array): Keypoints normalizados en el rango [-1, 1].
    """
    points = np.array(points)  # Asegurar que sea un array de NumPy

    # 1. Centrar por el centroide
    centroid = points.mean(axis=0)  # Centroide del frame
    centered_points = points - centroid

    # 2. Escalar por la distancia máxima desde el centroide
    max_distance = np.linalg.norm(centered_points, axis=1).max()  # Distancia máxima al centroide
    if max_distance == 0:
        max_distance = 1e-8  # Evitar divisiones por cero
    
    scaled_points = centered_points / max_distance  # Normalizar al rango [-1, 1]
    
    return scaled_points

#############################################################
# Graficas
def crear_grafica(historial):
    plt.plot(historial, marker='o', linestyle='-', color='b', label='Cambios entre frames')

    # Personalización de la gráfica
    
    plt.xlabel("Índice del Frame")
    plt.ylabel("Cambio")
    plt.axhline(0, color='gray', linestyle='--', linewidth=0.8)  # Línea en y=0
    plt.grid(alpha=0.3)
    #plt.legend()
    
    if len(key_points_interesantes) <= 12:
        plt.title("Cambios entre Frames 12 Key Points")
        ruta_graficas = r"Nuevo_codigo\Graficas_movimientos_entre_frames\12_key_points\\"
    else:  
        plt.title("Cambios entre Frames 24 Key Points")
        ruta_graficas = r"Nuevo_codigo\Graficas_movimientos_entre_frames\24_key_points\\"
    
    plt.savefig(ruta_graficas + os.path.basename(ruta_video).replace("mp4","png"), dpi=300) 

    # Mostrar la gráfica
    plt.show()
    
def grafica_histograma(historial):
    # Crear un histograma
    plt.figure(figsize=(10, 5))
    plt.hist(historial, bins=len(historial), color='blue', alpha=0.7, edgecolor='black')
    
    # Etiquetas y título del histograma
    plt.xlabel("Valores")
    plt.ylabel("Frecuencia")
    
    if len(key_points_interesantes) <= 12:
        plt.title("Histograma Cambios entre Frames: 12 Key Points")
        ruta_graficas = r"Nuevo_codigo\Graficas_movimientos_entre_frames\12_key_points\\"
    else:  
        plt.title("Histograma Cambios entre Frames: 24 Key Points")
        ruta_graficas = r"Nuevo_codigo\Graficas_movimientos_entre_frames\24_key_points\\"
    
    # Mostrar el histograma
    plt.show()


#####################################################################################################################
# Manejo DataSet

#############################################################
# Extraer Caracteristicas 

def split_video_to_labels_and_keypoints(video_path, intervals_file):
    # Leer el archivo de intervalos
    with open(intervals_file, 'r') as file:
        lines = file.readlines()

    # Cargar el video
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        print(f"Error: No se pudo abrir el video {video_path}")
        raise Exception("El video no se ha podido abrir correctamente")

    # Lista para almacenar los datos estructurados
    labels = []
    labels_key_points = []
    
    antiguo_label = None

    for line in lines:
        start_frame, end_frame, label = line.strip().split()
        start_frame, end_frame = math.ceil(int(start_frame) / 1000), math.ceil(int(end_frame) / 1000)

        # Establecer la posición inicial del frame
        cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)

        #print(f"Procesando frames para la etiqueta '{label}' desde el frame {start_frame} hasta {end_frame}...")
        
        if antiguo_label != label:
            
            #Cambio sin reconocimiento de keypoints
            if antiguo_label != None and np.any(np.array(key_points) == None):
                labels.pop()
            elif antiguo_label != None:
                labels_key_points.append(np.array(key_points))
                
            labels.append(label)
            key_points = []
            antiguo_label = label
            
        # Recorrer los frames del intervalo
        for frame_num in range(start_frame, end_frame):
            ret, frame = cap.read()
            if not ret:
                return (None,None)
            
            kp = lips_points_labios(frame)
            
            if not( np.any(np.array(kp) == None) or kp.size == 0):
                key_points.append(np.array(normalize_keypoints_frame(kp)))

    # Liberar recursos de OpenCV
    cap.release()
    #print("Procesamiento completado.")

    # Convertir la lista en un np.array estructurado
    return (np.array(labels),labels_key_points)
    
#############################################################
# Guardar leer Data_Set Refinado

def guardar_entrenamiento(labels, arrays, nombre_archivo):
    """
    Guarda las etiquetas y los arrays multidimensionales en un archivo de texto,
    agregándolos al final del archivo si ya existe.
    
    Args:
    labels (list): Lista de etiquetas.
    arrays (list): Lista de arrays de NumPy multidimensionales.
    nombre_archivo (str): Nombre del archivo donde se guardarán los datos.
    """
    try:
        with open(nombre_archivo, 'a') as f:  # Modo de adición ('a')
            for label, arr in zip(labels, arrays):
                f.write(f"{label}\n")  # Escribir la etiqueta
                for elm in arr:
                    np.savetxt(f, elm, delimiter=' ', fmt='%.6g')  # Guardar el array
                    f.write(f"{FIN_ELEMENTO}\n")
                f.write(f"\n{FIN_BLOQUE}\n")  # Separador entre bloques
    except Exception as e:
        raise Exception(f"Error al guardar los datos: {e}")
        
        
def leer_entrenamiento(nombre_archivo):
    """
    Lee las etiquetas y los arrays multidimensionales desde un archivo de texto,
    considerando los separadores FIN_ELEMENTO y FIN_BLOQUE.
    
    Args:
    nombre_archivo (str): Nombre del archivo desde donde se leerán los datos.
    
    Returns:
    tuple:
        - labels (list): Lista de etiquetas.
        - arrays (list): Lista de arrays de NumPy multidimensionales.
    """
    labels = []
    arrays = []
    try:
        with open(nombre_archivo, 'r') as f:
            while True:
                label = f.readline().strip()  # Leer la etiqueta
                if not label:  # Si no hay más etiquetas, terminar
                    break
                arr = []
                temp = []  # Para almacenar el sub-array actual
                while True:
                    line = f.readline().strip()
                    if line == FIN_BLOQUE:  # Fin del bloque
                        if temp:  # Guardar el último sub-array si existe
                            arr.append(np.array(temp))
                        break
                    elif line == FIN_ELEMENTO:  # Fin de un sub-array
                        if temp:  # Guardar el sub-array si existe
                            arr.append(np.array(temp))
                        temp = []  # Reiniciar el sub-array temporal
                    elif line:  # Evitar líneas vacías y procesar contenido
                        temp.append(list(map(float, line.split())))  # Convertir a flotantes
                if arr:
                    labels.append(label)
                    arrays.append(arr)  
                else:
                    print(f"Se ha recogido la la palabra {label}")
    except Exception as e:
        print(f"Error al leer los datos: {e}")
    
    return np.array(labels), arrays

def refinas_base_de_datos():
    archivo_refinado = r"DataSetRefinada\s1.txt"
    try:
        os.remove(archivo_refinado)
    except:
        pass
    # Especifica la carpeta que quieres listar
    folder_path_ali = r'DataSet\alignments\alignments\s1\\'
    folder_path_vid = r'DataSet\s1\s1\\'

    # Lista los archivos y directorios en la carpeta
    alis = os.listdir(folder_path_ali)
    vids = os.listdir(folder_path_vid)
    
    alis = [folder_path_ali + file for file in alis]
    vids = [folder_path_vid + file for file in vids]
    
    contador = 0
    num_archivos = len(alis)
    
    for i in range(len(alis)):
        contador += 1
        print(f"Procesando {contador} de {num_archivos}")
        labels, arrays = split_video_to_labels_and_keypoints(vids[i],alis[i])
        if labels is None:
            print("Error al cargar el frame, pasando de video")
        else:
            guardar_entrenamiento(labels, arrays, archivo_refinado)
            print("Video bien guardado")
        

    print("FINNN")
    
def cargamos_datos():
    archivo_refinado = r"DataSetRefinada\s1.txt"
    labels, arrays = leer_entrenamiento(archivo_refinado)
    print(labels[0])
    print(len(arrays[0]))
    #grafica_histograma(labels)
    
#################
# Estructura red

def calcular_limite_longitud(secuencias):
    """
    Calcula el límite de longitud para secuencias basado en el promedio + 2 desviaciones estándar.
    
    Args:
        secuencias (list of list): Lista de secuencias, donde cada secuencia es una lista de puntos clave o frames.
    
    Returns:
        int: Límite recomendado para la longitud de las secuencias.
    """
    longitudes = [len(seq) for seq in secuencias]
    promedio = np.mean(longitudes)
    desviacion_estandar = np.std(longitudes)
    limite = int(promedio + 2 * desviacion_estandar)
    return limite

def aplicar_padding(secuencias, longitud_objetivo):
    """
    Aplica padding a todas las secuencias para que tengan la misma longitud.
    
    Args:
        secuencias (list of list): Lista de secuencias, donde cada secuencia es una lista de puntos clave o frames.
        longitud_objetivo (int): Longitud fija deseada para todas las secuencias.
    
    Returns:
        np.array: Matriz con todas las secuencias rellenadas con padding (ceros).
    """
    secuencias_padded = []
    for secuencia in secuencias:
        secuencia = np.array(secuencia)
        # Si la secuencia es más corta que la longitud objetivo, agrega ceros al final
        if len(secuencia) < longitud_objetivo:
            padding = np.zeros(shape=(longitud_objetivo - len(secuencia),20,2)) 
            #print(secuencia.shape)
            
            secuencia_padded = np.concatenate((secuencia,padding))
            
        else:
            secuencia_padded = secuencia
        secuencias_padded.append(secuencia_padded)
    
    return np.array(secuencias_padded)

    
#####################################################################################################################
# Ejecucion expetimental, estudio de la varianza de frame y treshold
    
if __name__ == "__main__":
    archivo_refinado = r"DataSetRefinada\s1.txt"
    labels, arrays = leer_entrenamiento(archivo_refinado)
    
    # Define los hiperparámetros
    input_dim = len(key_points_interesantes)  # Número de keypoints por frame (ejemplo)
    longitud = calcular_limite_longitud(arrays)
    longitudes = [len(seq) for seq in arrays]
    
    classes = np.unique(labels).size 
    arrays_threshold = []
    labels_threshold = []
    
    for i in range(len(arrays)):
        if len(arrays[i])<=longitud:
            arrays_threshold.append(arrays[i])
            labels_threshold.append(labels[i])
              
    num_classes = np.unique(labels).size      # Número de palabras a reconocer
    
    time_steps = longitud  # Número de frames en cada secuencia
    
    # Crear un mapeo de etiquetas únicas a enteros
    unique_labels = np.unique(labels_threshold)
    label_to_int = {label: idx for idx, label in enumerate(unique_labels)}

    # Convertir las etiquetas usando el mapeo
    labels_threshold_int = [label_to_int[label] for label in labels_threshold]

    y_train = to_categorical(labels_threshold_int, num_classes=num_classes)
    
    X_padding = aplicar_padding(arrays_threshold,longitud)
    
    # Dividir en conjuntos de entrenamiento y validación
    X_train, X_val, y_train, y_val = train_test_split(X_padding, y_train, test_size=0.2, random_state=42)

    model = Sequential([
        # TimeDistributed para procesar las relaciones espaciales (keypoints)
        TimeDistributed(Conv1D(filters=32, kernel_size=3, activation='relu'), input_shape=(15, 20, 2)),
        TimeDistributed(MaxPooling1D(pool_size=2)),
        TimeDistributed(Flatten()),  # Reduce las dimensiones a (15, features)
        
        # LSTM para capturar patrones temporales
        LSTM(128, return_sequences=True),
        Dropout(0.3),
        BatchNormalization(),
        LSTM(64),
        Dropout(0.3),
        BatchNormalization(),
        
        # Capa densa intermedia
        Dense(64, activation='relu'),
        Dropout(0.3),
        
        # Capa de salida para clasificación
        Dense(num_classes, activation='softmax')
    ])

    # Compilación del modelo
    model.compile(optimizer='adam',
                loss='categorical_crossentropy',
                metrics=['accuracy'])

    # Mostrar resumen del modelo
    model.summary()

    # Entrenar el modelo
    epochs = 150
    batch_size = 32

    history = model.fit(
        X_train, y_train,
        validation_data=(X_val, y_val),
        epochs=epochs,
        batch_size=batch_size
    )

    # Graficar resultados
    plt.plot(history.history['accuracy'], label='Entrenamiento')
    plt.plot(history.history['val_accuracy'], label='Validación')
    plt.title('Precisión del modelo')
    plt.xlabel('Época')
    plt.ylabel('Precisión')
    plt.legend()
    plt.show()

    plt.plot(history.history['loss'], label='Entrenamiento')
    plt.plot(history.history['val_loss'], label='Validación')
    plt.title('Pérdida del modelo')
    plt.xlabel('Época')
    plt.ylabel('Pérdida')
    plt.legend()
    plt.show()

    # Evaluar el modelo
    loss, accuracy = model.evaluate(X_val, y_val)
    print(f"Pérdida: {loss}, Precisión: {accuracy}")

    # Guardar el modelo
    model.save('modelo_clasificador_lstm.h5')